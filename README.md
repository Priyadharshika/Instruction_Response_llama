# Instruction_Response_llama

ðŸ§  Model
We fine-tune LLaMA-13B using LoRA to reduce memory usage.

ðŸ”§ Hyperparameters:

| Hyperparameters                | Value |
|-----------------------|-------|
| Learning Rate   | 2e-4   |
| Batch Size   | 4 |
| Epochs      | 2 |
| Optimizer      | paged_adamw_32bit |

ðŸ“Š Results

ðŸ“Œ Performance Metrics

| Metric                | Score |
|-----------------------|-------|
| BertScore(Accuracy)   | x     |
| BertScore(F1-Score)   | 83.6% |
| BertScore(F1-Score)   | 83.6% |
| BertScore(F1-Score)   | 83.6% |

